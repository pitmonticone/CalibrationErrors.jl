<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Calibration · CalibrationErrors.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>CalibrationErrors.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../background/">Background</a></li><li class="current"><a class="toctext" href>Calibration</a><ul class="internal"><li><a class="toctext" href="#Motivation-1">Motivation</a></li><li><a class="toctext" href="#Definition-1">Definition</a></li><li><a class="toctext" href="#Measures-1">Measures</a></li></ul></li><li><a class="toctext" href="../estimators/">Estimators</a></li><li><span class="toctext">Examples</span><ul><li><a class="toctext" href="../generated/distribution/">Distribution</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Calibration</a></li></ul><a class="edit-page" href="https://github.com/devmotion/CalibrationErrors.jl/blob/master/docs/src/calibration.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Calibration</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Calibration-1" href="#Calibration-1">Calibration</a></h1><h2><a class="nav-anchor" id="Motivation-1" href="#Motivation-1">Motivation</a></h2><p>Ideally one would like to have a model that predicts the underlying probability distribution for almost every input, i.e., a model <span>$g$</span> such that almost always</p><div>\[    g(X) = \mu_{Y|X}(\cdot|X).\]</div><p>Unfortunately, if we try to infer the model from a finite data set of inputs and outputs that is usually not possible.</p><p>In safety-critical applications such as medical decision-making or autonomous driving, however, important decisions are based on the predictions of a model. Since we are not able to obtain the perfect model, the model has to satisfy other properties such that it is deemed trustworthy.</p><h2><a class="nav-anchor" id="Definition-1" href="#Definition-1">Definition</a></h2><p>One such property is calibration, which is also called reliability. Loosely speaking, if we repeatedly predict the same distribution for different pairs of inputs and outputs, we would like that in the long run the empirical distribution of the observed outputs is similar to the predicted probability distribution. This property guarantees that the predicted distribution is not only an arbitrary probability distribution but actually makes sense from a frequentist point of view.</p><p>A <a href="https://www.jstor.org/stable/2987588">classic example from the literature</a> is a weather forecaster who each morning predicts the probability that it will rain during the day. If we assume that the forecaster&#39;s predictions are observed for a long time, the forecaster is called calibrated &quot;if among those days for which his prediction is <span>$x$</span>, the long-run relative frequency of rain is also <span>$x$</span>&quot;.</p><h3><a class="nav-anchor" id="Common-notion-1" href="#Common-notion-1">Common notion</a></h3><p>Commonly (see, e.g, <a href="http://proceedings.mlr.press/v70/guo17a/guo17a.pdf">Guo et al. (2017)</a>), only calibration of the most-confident predictions <span>$\max_y g_y(x)$</span> of a model <span>$g$</span> is considered. According to this common notion a model is calibrated if almost always</p><div>\[    \mathbb{P}[Y = \textrm{arg} \, \max_y g_y(X) \,|\, \max_y g_y(X)] = \max_y g_y(X).\]</div><h3><a class="nav-anchor" id="Strong-notion-1" href="#Strong-notion-1">Strong notion</a></h3><p>According to the more general definition by <a href="https://rmets.onlinelibrary.wiley.com/doi/pdf/10.1002/qj.456">Bröcker (2009)</a> and <a href="http://proceedings.mlr.press/v89/vaicenavicius19a/vaicenavicius19a.pdf">Vaicenavicius et al. (2019)</a>, a probabilistic model <span>$g$</span> is calibrated if almost always</p><div>\[    \mathbb{P}[Y = y \,|\, g(X)] = g_y(X)\]</div><p>for all classes <span>$y$</span>.</p><p>For classification problems with more than two classes, this definition of calibration is stronger than the more common one above. By reducing the model and applying the strong notion to the simplified model, however, this definition still allows to investigate the calibration of the model with respect to only certain aspects of interest such as the calibration of the most-confident predictions.</p><p>Thus in this Julia package and its documentation, we always refer to the strong notion of calibration.</p><p>Let <span>$y_1, \ldots, y_m$</span> be the possible outputs. Then we can also define calibration in a vectorized form. Equivalently to the definition above, a model <span>$g$</span> is calibrated if and only if</p><div>\[    r(g(X)) - g(X) = 0\]</div><p>holds almost always, where</p><div>\[    r(\xi) := (\mathbb{P}[Y = y_1 \,|\, g(X) = \xi], \ldots, \mathbb{P}[Y = y_m \,|\, g(X) = \xi])\]</div><p>denotes the so-called calibration function.</p><h2><a class="nav-anchor" id="Measures-1" href="#Measures-1">Measures</a></h2><p>Calibration measures allow a more fine-tuned analysis of calibration and enable comparisons of calibration of different models. Intuitively, calibration measures quantify the deviation of the left and right hand side in the definitions above.</p><h3><a class="nav-anchor" id="Expected-calibration-error-(ECE)-1" href="#Expected-calibration-error-(ECE)-1">Expected calibration error (ECE)</a></h3><p>The most common calibration measure is the so-called expected calibration error (ECE) (see, e.g., <a href="http://proceedings.mlr.press/v70/guo17a/guo17a.pdf">Guo et al. (2017)</a>). Informally, it is defined as the average distance between the left and right hand side of the definition above with respect to some metric. Mathematically, the expected calibration of model <span>$g$</span> with respect to distance measure <span>$d$</span> is defined as</p><div>\[    \mathrm{ECE}[d, g] := \mathbb{E}[d(r(g(X)), g(X))].\]</div><p>Here <span>$d$</span> could be, e.g., the cityblock distance, the total variation distance, or the squared Euclidean distance.</p><p>If <span>$d(p, q) = 0$</span> if and only if <span>$p = q$</span>, then the ECE of model <span>$g$</span> with respect to distance measure <span>$d$</span> is zero if and only if <span>$g$</span> is calibrated.</p><h3><a class="nav-anchor" id="Calibration-error-(CE)-1" href="#Calibration-error-(CE)-1">Calibration error (CE)</a></h3><p>More generally, Widmann et al. (2019) define the calibration error (CE) of a model <span>$g$</span> with respect to a function class <span>$\mathcal{F} \subset \{f \colon \Delta^m \to \mathbb{R}^m\}$</span> as</p><div>\[    \mathrm{CE}[\mathcal{F}, g] := \sup_{f \in \mathcal{F}} \mathbb{E}[(r(g(X)) - g(X))^\intercal f(g(X))].\]</div><p>If model <span>$g$</span> is calibrated, then the CE is zero, regardless of the choice of <span>$\mathcal{F}$</span>. However, for some function spaces (e.g., for <span>$\mathcal{F} = \{0\}$</span>) the CE is zero even if <span>$g$</span> is not calibrated.</p><p>Interestingly, the ECE with respect to the cityblock distance, the total variation distance, and the squared Euclidean distance are all special cases of the CE (Widmann et al. (2019)).</p><h3><a class="nav-anchor" id="Kernel-calibration-error-(KCE)-1" href="#Kernel-calibration-error-(KCE)-1">Kernel calibration error (KCE)</a></h3><p>The kernel calibration error (KCE) is another special case of the CE, in which the unit ball of a reproducing kernel Hilbert space (RKHS) of vector-valued functions is chosen as function space <span>$\mathcal{F}$</span>.</p><p>A RKHS of vector-valued functions <span>$f \colon \Delta^m \to \mathbb{R}^m$</span> can be identified with a unique matrix-valued kernel <span>$k \colon \Delta^m \times \Delta^m \to \mathbb{R}^{m \times m}$</span>. Then the KCE of a model <span>$g$</span> with respect to kernel <span>$k$</span> is defined as</p><div>\[    \mathrm{KCE}[k, g] := \mathrm{CE}[\mathcal{F}, g],\]</div><p>where <span>$\mathcal{F}$</span> is the unit ball of the RKHS corresponding to kernel <span>$k$</span>.</p><p>As Widmann et al. (2019) show, for a large class of kernels (so-called universal kernels) the KCE is zero if and only if the model <span>$g$</span> is calibrated. Moreover, the KCE can be formulated in terms of the kernel <span>$k$</span> as</p><div>\[    \mathrm{KCE}[k, g] := {\left(\mathbb{E}[(e_Y - g(X))^{\intercal} k(g(X), g(X&#39;)) (e_{Y&#39;} - g(X&#39;))]\right)}^{1/2},\]</div><p>where <span>$(X&#39;,Y&#39;)$</span> is an independent copy of <span>$(X,Y)$</span> and <span>$e_i$</span> denotes the <span>$i$</span>th unit vector.</p><p>The so-called maximum mean calibration error (MMCE), proposed by <a href="http://proceedings.mlr.press/v80/kumar18a/kumar18a.pdf">Kumar et al. (2018)</a>, can be viewed as a special case of the KCE, in which only the most-confident predictions are considered (Widmann et al. (2019)).</p><footer><hr/><a class="previous" href="../background/"><span class="direction">Previous</span><span class="title">Background</span></a><a class="next" href="../estimators/"><span class="direction">Next</span><span class="title">Estimators</span></a></footer></article></body></html>
